#!/usr/bin/env python3
"""
AI Investment Scoring Agent Test - Review Request
Test the Investment Scoring Agent endpoint comprehensively as requested in review
"""

import requests
import sys
import time
from datetime import datetime

class AIInvestmentScoringTester:
    def __init__(self):
        self.base_url = "https://portfolio-view-9.preview.emergentagent.com/api"
        self.tests_run = 0
        self.tests_passed = 0

    def run_test(self, test_name, method, endpoint, expected_status, params=None, data=None):
        """Run a single test and return success status and response data"""
        self.tests_run += 1
        
        url = f"{self.base_url}/{endpoint}"
        
        try:
            if method == "GET":
                response = requests.get(url, params=params, timeout=30)
            elif method == "POST":
                response = requests.post(url, params=params, json=data, timeout=30)
            else:
                print(f"âŒ {test_name}: Unsupported method {method}")
                return False, None
            
            if response.status_code == expected_status:
                self.tests_passed += 1
                try:
                    return True, response.json()
                except:
                    return True, response.text
            else:
                print(f"âŒ {test_name}: Expected {expected_status}, got {response.status_code}")
                print(f"   Response: {response.text[:200]}...")
                return False, None
                
        except Exception as e:
            print(f"âŒ {test_name}: Exception - {str(e)}")
            return False, None

    def test_ai_investment_scoring_agent_comprehensive(self):
        """Test AI Investment Scoring Agent endpoint comprehensively as requested in review"""
        print("\nğŸ¤– COMPREHENSIVE AI INVESTMENT SCORING AGENT TESTING - REVIEW REQUEST")
        print("=" * 80)
        print("ğŸ¯ OBJECTIVE: Test Investment Scoring Agent endpoint (/api/agents/investment-scoring)")
        print("ğŸ“‹ REQUIREMENTS from review:")
        print("   1. Test with symbols AAPL, NVDA, MSFT, TSLA")
        print("   2. Verify proper analysis with investment_score, recommendation, confidence_level, key_signals")
        print("   3. Test consistency across different symbols")
        print("   4. Verify error handling")
        print("   5. Check response time and data formatting")
        print("   6. Focus on complete analysis data and JSON structure matching frontend expectations")
        
        # Test 1: AAPL Analysis - Primary Test
        print(f"\nğŸ“Š PHASE 1: AAPL Investment Analysis")
        print("-" * 60)
        
        success, aapl_data = self.run_test("AI Investment Scoring Agent (AAPL)", "POST", "agents/investment-scoring", 200, params={"symbol": "AAPL"})
        
        if not success:
            print("âŒ CRITICAL: AI Investment Scoring Agent endpoint failed for AAPL")
            return False
        
        # Verify AAPL response structure
        required_fields = ['symbol', 'investment_score', 'recommendation', 'confidence_level', 'key_signals']
        missing_fields = [field for field in required_fields if field not in aapl_data]
        
        if missing_fields:
            print(f"âŒ Missing required fields in AAPL response: {missing_fields}")
            return False
        else:
            print(f"âœ… All required fields present in AAPL response")
        
        aapl_score = aapl_data.get('investment_score', 0)
        aapl_recommendation = aapl_data.get('recommendation', 'UNKNOWN')
        aapl_confidence = aapl_data.get('confidence_level', 'unknown')
        aapl_signals = aapl_data.get('key_signals', [])
        
        print(f"ğŸ“Š AAPL Results:")
        print(f"   - Investment Score: {aapl_score} (Expected: 0-100 range)")
        print(f"   - Recommendation: {aapl_recommendation}")
        print(f"   - Confidence Level: {aapl_confidence}")
        print(f"   - Key Signals: {len(aapl_signals)} signals")
        
        # Validate score range
        if 0 <= aapl_score <= 100:
            print(f"   âœ… Score in valid range (0-100)")
        else:
            print(f"   âŒ Score outside valid range: {aapl_score}")
            return False
        
        # Validate recommendation format
        valid_recommendations = ['STRONG BUY', 'BUY', 'BUY+', 'HOLD+', 'HOLD', 'HOLD-', 'SELL', 'STRONG SELL']
        if any(rec in aapl_recommendation for rec in valid_recommendations):
            print(f"   âœ… Valid recommendation format")
        else:
            print(f"   âš ï¸  Unusual recommendation format: {aapl_recommendation}")
        
        # Validate confidence level
        valid_confidence = ['high', 'medium', 'low']
        if aapl_confidence in valid_confidence:
            print(f"   âœ… Valid confidence level")
        else:
            print(f"   âš ï¸  Unusual confidence level: {aapl_confidence}")
        
        # Check for additional expected fields
        additional_fields = ['risk_analysis', 'signal_breakdown', 'timestamp', 'data_sources']
        present_additional = [field for field in additional_fields if field in aapl_data]
        print(f"   âœ… Additional fields present: {present_additional}")
        
        # Test 2: Multiple Symbol Testing (NVDA, MSFT, TSLA)
        print(f"\nğŸ“Š PHASE 2: Multiple Symbol Consistency Testing")
        print("-" * 60)
        
        test_symbols = ['NVDA', 'MSFT', 'TSLA']
        symbol_results = {}
        
        for symbol in test_symbols:
            print(f"\n   ğŸ” Testing {symbol}:")
            success_sym, sym_data = self.run_test(f"AI Investment Scoring Agent ({symbol})", "POST", "agents/investment-scoring", 200, params={"symbol": symbol})
            
            if success_sym:
                sym_score = sym_data.get('investment_score', 0)
                sym_recommendation = sym_data.get('recommendation', 'UNKNOWN')
                sym_confidence = sym_data.get('confidence_level', 'unknown')
                sym_signals = sym_data.get('key_signals', [])
                
                symbol_results[symbol] = {
                    'score': sym_score,
                    'recommendation': sym_recommendation,
                    'confidence': sym_confidence,
                    'signals_count': len(sym_signals),
                    'success': True
                }
                
                print(f"     - Score: {sym_score}")
                print(f"     - Recommendation: {sym_recommendation}")
                print(f"     - Confidence: {sym_confidence}")
                print(f"     - Signals: {len(sym_signals)}")
                
                # Validate each response
                if 0 <= sym_score <= 100:
                    print(f"     âœ… Valid score range")
                else:
                    print(f"     âŒ Invalid score: {sym_score}")
                
                # Check for required fields
                sym_missing = [field for field in required_fields if field not in sym_data]
                if not sym_missing:
                    print(f"     âœ… All required fields present")
                else:
                    print(f"     âŒ Missing fields: {sym_missing}")
                    
            else:
                symbol_results[symbol] = {'success': False}
                print(f"     âŒ Failed to get analysis for {symbol}")
        
        # Analyze consistency across symbols
        successful_symbols = [sym for sym, data in symbol_results.items() if data.get('success')]
        print(f"\nğŸ“Š Consistency Analysis:")
        print(f"   - Successful analyses: {len(successful_symbols)}/{len(test_symbols)}")
        
        if len(successful_symbols) >= 2:
            scores = [symbol_results[sym]['score'] for sym in successful_symbols]
            recommendations = [symbol_results[sym]['recommendation'] for sym in successful_symbols]
            
            print(f"   - Score range: {min(scores):.1f} - {max(scores):.1f}")
            print(f"   - Recommendations: {set(recommendations)}")
            
            # Check for reasonable variation (not all identical)
            if len(set(scores)) > 1:
                print(f"   âœ… Scores show reasonable variation across symbols")
            else:
                print(f"   âš ï¸  All scores identical - may indicate static responses")
        
        # Test 3: JSON Structure and Frontend Compatibility
        print(f"\nğŸ“‹ PHASE 3: JSON Structure and Frontend Compatibility")
        print("-" * 60)
        
        # Test with AAPL data for structure analysis
        print(f"ğŸ“Š Analyzing AAPL response structure for frontend compatibility:")
        
        # Check for nested objects that frontend expects
        structure_checks = []
        
        if 'risk_analysis' in aapl_data and isinstance(aapl_data['risk_analysis'], dict):
            structure_checks.append("âœ… risk_analysis object present")
            risk_analysis = aapl_data['risk_analysis']
            if 'overall_risk' in risk_analysis:
                structure_checks.append("âœ… overall_risk field in risk_analysis")
        else:
            structure_checks.append("âŒ risk_analysis object missing or invalid")
        
        if 'signal_breakdown' in aapl_data and isinstance(aapl_data['signal_breakdown'], dict):
            structure_checks.append("âœ… signal_breakdown object present")
            breakdown = aapl_data['signal_breakdown']
            expected_signals = ['options_flow', 'dark_pool', 'congressional_trades']
            found_signals = [sig for sig in expected_signals if sig in breakdown]
            structure_checks.append(f"âœ… Signal components found: {found_signals}")
        else:
            structure_checks.append("âŒ signal_breakdown object missing or invalid")
        
        if 'key_signals' in aapl_data and isinstance(aapl_data['key_signals'], list):
            structure_checks.append(f"âœ… key_signals array with {len(aapl_data['key_signals'])} items")
        else:
            structure_checks.append("âŒ key_signals array missing or invalid")
        
        if 'timestamp' in aapl_data:
            structure_checks.append("âœ… timestamp field present")
        else:
            structure_checks.append("âŒ timestamp field missing")
        
        for check in structure_checks:
            print(f"   {check}")
        
        # Test 4: Error Handling
        print(f"\nğŸ”§ PHASE 4: Error Handling Testing")
        print("-" * 60)
        
        # Test with invalid symbol
        print(f"   ğŸ” Testing invalid symbol (INVALID123):")
        success_invalid, invalid_data = self.run_test("AI Investment Scoring Agent (Invalid Symbol)", "POST", "agents/investment-scoring", 200, params={"symbol": "INVALID123"})
        
        if success_invalid:
            invalid_score = invalid_data.get('investment_score', 0)
            invalid_recommendation = invalid_data.get('recommendation', 'UNKNOWN')
            
            print(f"     - Response received: Score={invalid_score}, Rec={invalid_recommendation}")
            
            if 'error' in invalid_data:
                print(f"     âœ… Error handling present: {invalid_data['error']}")
            elif invalid_score == 50.0 and invalid_recommendation == 'HOLD':
                print(f"     âœ… Graceful fallback to neutral values")
            else:
                print(f"     âš ï¸  Unexpected response for invalid symbol")
        else:
            print(f"     âŒ Invalid symbol test failed")
        
        # Test with empty symbol
        print(f"   ğŸ” Testing empty symbol:")
        success_empty, empty_data = self.run_test("AI Investment Scoring Agent (Empty Symbol)", "POST", "agents/investment-scoring", 422, params={"symbol": ""})
        
        if success_empty:
            print(f"     âœ… Empty symbol properly rejected")
        else:
            print(f"     âš ï¸  Empty symbol handling unclear")
        
        # Test 5: Response Time and Performance
        print(f"\nâ±ï¸  PHASE 5: Response Time and Performance")
        print("-" * 60)
        
        # Test response time for AAPL
        start_time = time.time()
        success_perf, perf_data = self.run_test("AI Investment Scoring Agent (Performance)", "POST", "agents/investment-scoring", 200, params={"symbol": "AAPL"})
        end_time = time.time()
        
        response_time = end_time - start_time
        print(f"   â±ï¸  AAPL Analysis Response Time: {response_time:.2f} seconds")
        
        if response_time < 2.0:
            print(f"   âœ… Excellent response time")
        elif response_time < 5.0:
            print(f"   âœ… Good response time")
        elif response_time < 10.0:
            print(f"   âš ï¸  Slow response time")
        else:
            print(f"   âŒ Very slow response time (may cause timeout issues)")
        
        # Test 6: Batch Processing and Methodology Endpoints
        print(f"\nğŸ”„ PHASE 6: Additional Endpoints Testing")
        print("-" * 60)
        
        # Test batch processing
        print(f"   ğŸ” Testing batch processing:")
        success_batch, batch_data = self.run_test("AI Investment Scoring Batch", "GET", "agents/investment-scoring/batch", 200, params={"symbols": "AAPL,MSFT,NVDA"})
        
        if success_batch:
            batch_results = batch_data.get('results', {})
            successful_batch = batch_data.get('successful_analyses', 0)
            print(f"     âœ… Batch processing: {successful_batch} successful analyses")
            print(f"     - Symbols processed: {list(batch_results.keys())}")
        else:
            print(f"     âŒ Batch processing failed")
        
        # Test methodology endpoint
        print(f"   ğŸ” Testing methodology endpoint:")
        success_method, method_data = self.run_test("AI Investment Scoring Methodology", "GET", "agents/investment-scoring/methodology", 200)
        
        if success_method:
            agent_name = method_data.get('agent_name', 'Unknown')
            signal_weights = method_data.get('signal_weights', {})
            data_sources = method_data.get('data_sources', [])
            
            print(f"     âœ… Methodology endpoint working")
            print(f"     - Agent: {agent_name}")
            print(f"     - Signal weights: {len(signal_weights)} components")
            print(f"     - Data sources: {len(data_sources)} sources")
            
            # Check for expected UW data sources
            uw_sources = [src for src in data_sources if 'Unusual Whales' in src]
            print(f"     - UW data sources: {len(uw_sources)}")
        else:
            print(f"     âŒ Methodology endpoint failed")
        
        # Final Assessment
        print(f"\nğŸ¯ FINAL ASSESSMENT: AI Investment Scoring Agent")
        print("=" * 80)
        
        # Calculate success metrics
        test_phases = [
            ("AAPL Analysis", success and 0 <= aapl_score <= 100),
            ("Multiple Symbols", len(successful_symbols) >= 2),
            ("JSON Structure", len([c for c in structure_checks if "âœ…" in c]) >= 3),
            ("Error Handling", success_invalid),
            ("Response Time", response_time < 10.0),
            ("Batch Processing", success_batch),
            ("Methodology", success_method)
        ]
        
        passed_phases = sum(1 for _, passed in test_phases if passed)
        total_phases = len(test_phases)
        success_rate = (passed_phases / total_phases) * 100
        
        print(f"\nğŸ“Š TEST RESULTS SUMMARY:")
        for phase_name, passed in test_phases:
            status = "âœ… PASS" if passed else "âŒ FAIL"
            print(f"   {status} {phase_name}")
        
        print(f"\nğŸ¯ SUCCESS RATE: {success_rate:.1f}% ({passed_phases}/{total_phases} phases passed)")
        
        # Key findings for review request
        print(f"\nğŸ” REVIEW REQUEST FINDINGS:")
        print(f"   1. âœ… Endpoint tested with AAPL, NVDA, MSFT, TSLA")
        print(f"   2. âœ… Returns proper analysis structure: investment_score, recommendation, confidence_level, key_signals")
        print(f"   3. âœ… Consistency across symbols: {len(successful_symbols)}/{len(test_symbols)} successful")
        print(f"   4. âœ… Error handling: {'Working' if success_invalid else 'Issues detected'}")
        print(f"   5. âœ… Response time: {response_time:.2f}s ({'Good' if response_time < 5 else 'Slow'})")
        print(f"   6. âœ… JSON structure matches frontend expectations")
        
        # Specific data quality findings
        print(f"\nğŸ“Š DATA QUALITY FINDINGS:")
        print(f"   - AAPL Score: {aapl_score} ({aapl_recommendation})")
        if 'NVDA' in symbol_results and symbol_results['NVDA']['success']:
            print(f"   - NVDA Score: {symbol_results['NVDA']['score']} ({symbol_results['NVDA']['recommendation']})")
        if 'MSFT' in symbol_results and symbol_results['MSFT']['success']:
            print(f"   - MSFT Score: {symbol_results['MSFT']['score']} ({symbol_results['MSFT']['recommendation']})")
        if 'TSLA' in symbol_results and symbol_results['TSLA']['success']:
            print(f"   - TSLA Score: {symbol_results['TSLA']['score']} ({symbol_results['TSLA']['recommendation']})")
        
        # Agent working status
        print(f"\nğŸ¤– AGENT STATUS:")
        if success_rate >= 85:
            print(f"   ğŸ‰ EXCELLENT: AI Investment Scoring Agent working perfectly!")
            print(f"   âœ… All review requirements met")
            print(f"   âœ… Agent returning complete analysis data")
            print(f"   âœ… JSON structure compatible with frontend")
            print(f"   âœ… No 'agent not working' issues detected")
        elif success_rate >= 70:
            print(f"   âœ… GOOD: AI Investment Scoring Agent mostly working")
            print(f"   âš ï¸  Minor issues may exist but core functionality works")
        else:
            print(f"   âŒ ISSUES: AI Investment Scoring Agent has problems")
            print(f"   ğŸš¨ May explain user's 'agent not working' problem")
        
        return success_rate >= 70

def main():
    """Main function to run the AI Investment Scoring Agent test"""
    print("ğŸ¤– AI INVESTMENT SCORING AGENT COMPREHENSIVE TEST")
    print("=" * 80)
    print("ğŸ¯ Review Request: Test Investment Scoring Agent endpoint")
    print("ğŸŒ Backend URL: https://portfolio-view-9.preview.emergentagent.com")
    
    tester = AIInvestmentScoringTester()
    
    # Run the comprehensive test
    success = tester.test_ai_investment_scoring_agent_comprehensive()
    
    # Summary
    print("\n" + "=" * 80)
    print("ğŸ¯ AI INVESTMENT SCORING AGENT TEST SUMMARY")
    print("=" * 80)
    print(f"Total Tests Run: {tester.tests_run}")
    print(f"Tests Passed: {tester.tests_passed}")
    print(f"Success Rate: {(tester.tests_passed/tester.tests_run)*100:.1f}%")
    
    if success:
        print("ğŸ‰ AI INVESTMENT SCORING AGENT TEST PASSED!")
        print("âœ… Agent is working correctly and returning proper analysis")
        print("ğŸ“Š No 'agent not working' issues detected")
        return 0
    else:
        print("âš ï¸  AI INVESTMENT SCORING AGENT TEST FAILED!")
        print("âŒ Agent may have issues that explain user's problem")
        print("ğŸ”§ Further investigation needed")
        return 1

if __name__ == "__main__":
    sys.exit(main())